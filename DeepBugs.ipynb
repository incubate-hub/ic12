{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "ybAlQ2RfV5R1",
    "outputId": "1285bf2f-5512-4148-e68e-2332fb9bafaa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1w7KZ5ugVfcz4RGsY2feSalH9xpa_JFLh\n",
      "To: C:\\Users\\RASMITHA\\DeepBugs-master\\DeepBugs_data.tar.gz\n",
      "\n",
      "  0%|          | 0.00/20.1M [00:00<?, ?B/s]\n",
      "  3%|2         | 524k/20.1M [00:00<00:05, 3.38MB/s]\n",
      " 10%|#         | 2.10M/20.1M [00:00<00:02, 6.70MB/s]\n",
      " 18%|#8        | 3.67M/20.1M [00:00<00:01, 9.34MB/s]\n",
      " 23%|##3       | 4.72M/20.1M [00:00<00:01, 9.05MB/s]\n",
      " 34%|###3      | 6.82M/20.1M [00:00<00:01, 11.3MB/s]\n",
      " 42%|####1     | 8.39M/20.1M [00:00<00:01, 11.3MB/s]\n",
      " 49%|####9     | 9.96M/20.1M [00:00<00:00, 11.3MB/s]\n",
      " 57%|#####7    | 11.5M/20.1M [00:01<00:00, 11.5MB/s]\n",
      " 65%|######5   | 13.1M/20.1M [00:01<00:00, 11.2MB/s]\n",
      " 73%|#######2  | 14.7M/20.1M [00:01<00:00, 11.2MB/s]\n",
      " 81%|########  | 16.3M/20.1M [00:01<00:00, 11.2MB/s]\n",
      " 88%|########8 | 17.8M/20.1M [00:01<00:00, 11.2MB/s]\n",
      " 96%|#########6| 19.4M/20.1M [00:01<00:00, 11.1MB/s]\n",
      "100%|##########| 20.1M/20.1M [00:01<00:00, 10.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/uc?id=1w7KZ5ugVfcz4RGsY2feSalH9xpa_JFLh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mwQ1KhLQa5tL"
   },
   "outputs": [],
   "source": [
    "!tar -xzf DeepBugs_data.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmrNZLM1Sih-"
   },
   "source": [
    "The data are function calls extracted from open-source JavaScript code. Let's read the JSON data into our Python-based learning code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CiewuASiYCDa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "path = os.path.abspath(\"C:/Users/RASMITHA/DeepBugs-master/DeepBugs_data/calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9tIjdWO1ZjCC",
    "outputId": "c9d8ac83-776a-4e14-9bc1-8b501ad12e24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have read 28005 function calls\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "calls = []\n",
    "for file in os.listdir(\"DeepBugs_data/calls\"):\n",
    "  with open(os.path.join(\"DeepBugs_data/calls\", file), encoding='utf-8') as fp:\n",
    "    calls.extend(json.load(fp))\n",
    "\n",
    "print(f\"Have read {len(calls)} function calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4UtOgb6TZFo"
   },
   "source": [
    "We'll also use a pre-trained embedding of code tokens. It's a Word2Vec model trained on tokenized JavaScript code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bHTH0jNwc59S",
    "outputId": "85d0daa2-6ea0-40ff-93bc-1903e182306d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have loaded 9930 token embeddings.\n"
     ]
    }
   ],
   "source": [
    "with open(\"DeepBugs_data/token_to_vector.json\") as fp:\n",
    "  type_to_vector = json.load(fp)\n",
    "\n",
    "print(f\"Have loaded {len(type_to_vector)} token embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "b_oiHx4HcArX",
    "outputId": "7520c3de-c31d-49c9-e785-15a084a233a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21592 training examples\n",
      "2400 validation examples\n"
     ]
    }
   ],
   "source": [
    "xs = []   # Inputs given to the model: Each element is\n",
    "          #   the vector representation of a function call.\n",
    "ys = []   # Outputs expected from the model: For each\n",
    "          #   call, predict the probability that it's buggy.\n",
    "\n",
    "for call in calls:\n",
    "  if (call[\"callee\"] in type_to_vector and\n",
    "      call[\"arguments\"][0] in type_to_vector and\n",
    "      call[\"arguments\"][1] in type_to_vector):\n",
    "    callee_vec = type_to_vector[call[\"callee\"]]\n",
    "    arg1_vec = type_to_vector[call[\"arguments\"][0]]\n",
    "    arg2_vec = type_to_vector[call[\"arguments\"][1]]\n",
    "\n",
    "    # Positive, i.e., correct example\n",
    "    x_correct = callee_vec + arg1_vec + arg2_vec\n",
    "    # Negative, i.e., buggy example\n",
    "    x_buggy = callee_vec + arg2_vec + arg1_vec\n",
    "\n",
    "    xs.append(x_correct)\n",
    "    ys.append(0)  # Probability that buggy is 0\n",
    "    xs.append(x_buggy)\n",
    "    ys.append(1)  # Probability that buggy is 1\n",
    "\n",
    "# Split into training and validation data\n",
    "nb_training = int(0.9*len(xs))\n",
    "xs_training = np.array(xs[:nb_training])\n",
    "ys_training = np.array(ys[:nb_training])\n",
    "xs_validation = np.array(xs[nb_training:])\n",
    "ys_validation = np.array(ys[nb_training:])\n",
    "\n",
    "print(f\"{len(xs_training)} training examples\")\n",
    "print(f\"{len(xs_validation)} validation examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "lFoC7_ZjeT3S",
    "outputId": "852274a6-5927-4426-e14a-35036de9f483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "216/216 [==============================] - 4s 9ms/step - loss: 0.4991 - accuracy: 0.7457\n",
      "Epoch 2/5\n",
      "216/216 [==============================] - 2s 9ms/step - loss: 0.3501 - accuracy: 0.8371\n",
      "Epoch 3/5\n",
      "216/216 [==============================] - 2s 9ms/step - loss: 0.2811 - accuracy: 0.8761\n",
      "Epoch 4/5\n",
      "216/216 [==============================] - 2s 9ms/step - loss: 0.2423 - accuracy: 0.8942\n",
      "Epoch 5/5\n",
      "216/216 [==============================] - 2s 9ms/step - loss: 0.2163 - accuracy: 0.9036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ff63245f40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_length = len(xs[0])\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.2, input_shape=(x_length,)))\n",
    "model.add(Dense(200, input_dim=x_length, activation=\"relu\", kernel_initializer='normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\", kernel_initializer='normal'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(xs_training, ys_training, batch_size=100, epochs=5, verbose=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "w_wARBIyive8",
    "outputId": "6f2a81d3-2c07-41df-942f-f1131887b4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 1s 4ms/step - loss: 0.5137 - accuracy: 0.7621\n",
      "Validation accuracy: 0.7620833516120911\n"
     ]
    }
   ],
   "source": [
    "validation_stats = model.evaluate(xs_validation, ys_validation)\n",
    "print(f\"Validation accuracy: {validation_stats[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3FvUzJ15XEMR"
   },
   "source": [
    "## Using the Learned Bug Detection Model\n",
    "\n",
    "Once trained, we can query the model with a given function call. In a full implementation, the model would reason about calls extracted from JavaScript code. Here, we simply give the callee and arguments as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1KnyjO-ojXh0",
    "outputId": "4eab28b8-5d8f-4b35-ddf4-41325e6893db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 366ms/step\n",
      "Call is buggy with probability 0.9495\n"
     ]
    }
   ],
   "source": [
    "# Function call: setTimeout(delay, fn)\n",
    "callee = \"ID:setTimeout\"  # Prefix \"ID:\" is to indicate that it's an identifier.\n",
    "arg1 = \"ID:delay\"\n",
    "arg2 = \"ID:fn\"\n",
    "\n",
    "x = type_to_vector[callee] + type_to_vector[arg1] + type_to_vector[arg2]\n",
    "xs = np.array([x])\n",
    "\n",
    "buggy_probabilities = model.predict(xs)\n",
    "print(f\"Call is buggy with probability {str(round(buggy_probabilities[0][0], 4))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQMRJezRIP46CCEx8ouxt1",
   "collapsed_sections": [],
   "name": "DeepBugs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
